{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c6272e8-cf31-4376-a2e3-e4fa91ac01c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "88f73782-76c0-4fa7-85cf-08d8d0f0f385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE or replace TABLE data_engineering_practice.sql.employees (\n",
    "    emp_id INT,\n",
    "    emp_name VARCHAR(50),\n",
    "    department VARCHAR(50),\n",
    "    salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO data_engineering_practice.sql.employees VALUES\n",
    "(1, 'Amit',   'HR',      40000),\n",
    "(2, 'Neha',   'HR',      50000),\n",
    "(3, 'Ritu',   'HR',      50000),\n",
    "(4, 'Raj',    'IT',      60000),\n",
    "(5, 'Simran', 'IT',      70000),\n",
    "(6, 'Vikram', 'IT',      70000),\n",
    "(7, 'Arjun',  'Finance', 45000),\n",
    "(8, 'Meena',  'Finance', 55000),\n",
    "(9, 'Kabir',  'Finance', 55000);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22858eb8-2ff9-4fa0-93bb-3745107b07f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. ROW_NUMBER()\n",
    "\n",
    "Gives a unique number to each row within a group based on order. Even if two rows tie, they still get different numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3729477-d006-404a-85d9-666f7fcc4880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) AS row_num\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>In each department, employees are sorted by salary (highest → lowest).\n",
    ">>Then they are numbered 1, 2, 3 … without skipping.\n",
    ">>Useful when you want to pick the top-N employees in each department.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "673d71e2-9e8d-43fb-bdc2-157eb0baed1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. RANK()\n",
    "\n",
    "Similar to ROW_NUMBER(), but if two rows tie, they get the same rank. The next rank jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947a1f42-6740-48b6-bab2-ed0b3222cb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS rank_pos\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>If two employees have the same salary, both are rank 1.\n",
    ">>The next employee will get rank 3, not 2.\n",
    ">>Useful in contests or leaderboards where ties share the same position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6d650cb-db9d-4de1-8ee8-4cf27766deea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. DENSE_RANK()\n",
    "\n",
    "Like RANK(), but it doesn’t skip numbers after ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c219c5ef-64b6-4501-8254-731e608db68a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS dense_rank_pos\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>Neha & Ritu both rank 1, Amit becomes rank 2 (not 3).\n",
    ">>Keeps numbers compact.\n",
    ">>Often used in reporting when you don’t want gaps in rank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56cae39-4389-4445-8851-ab113da0b92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. NTILE(n)\n",
    "\n",
    "Splits rows into n roughly equal groups (buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbcbcc9-7ab2-4894-8d18-8075a5bcca08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       NTILE(3) OVER (ORDER BY salary DESC) AS bucket\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cab3b60-d924-485f-9313-3eaa9a8eb203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. LAG()\n",
    "\n",
    "Fetches the previous row’s value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef3d3f5-0a8b-4971-adf3-4fb048edebaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       LAG(salary) OVER (ORDER BY salary) AS prev_salary\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For each employee, shows what the previous employee’s salary was.\n",
    ">>First row has NULL because no one is before it.\n",
    ">>Useful for calculating differences between rows (e.g. salary increase from previous).*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5325def0-58ce-44f7-94ba-8aa15666c501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. LEAD()\n",
    "\n",
    "Fetches the next row’s value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64f534f1-f37c-4138-8717-484c5eeac557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       LEAD(salary) OVER (ORDER BY salary) AS next_salary\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For each employee, shows what the next employee’s salary is.\n",
    ">>Last row has NULL because no one is after it.\n",
    ">>Useful for comparing current vs. next record.*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cf7195c-f3e4-40db-a8f7-e9872336cbf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 7. SUM() / AVG() with OVER\n",
    "\n",
    "Aggregate functions over a partition, but rows are not collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b08e0d3c-082d-4984-9986-b7d295f01a81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       SUM(salary) OVER (PARTITION BY department) AS dept_total,\n",
    "       AVG(salary) OVER (PARTITION BY department) AS dept_avg\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For every employee, you see their department’s total & average salary.\n",
    ">>Unlike GROUP BY, you don’t lose row-level detail.\n",
    ">>Perfect for showing both employee-level and group-level info in one query.*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d0000aa-80b1-4800-ba54-77bc9bb4a3bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8. Running Total (Cumulative SUM)\n",
    "\n",
    "Keeps adding row by row, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f04d01ef-7a2b-45c3-9434-bf418b1ea62d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       SUM(salary) OVER (ORDER BY salary\n",
    "                         ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>Salaries are ordered (lowest → highest).\n",
    ">>Running total is computed row by row.\n",
    ">>Useful for things like cumulative sales or progressive totals.\n",
    "\n",
    ">>UNBOUNDED PRECEDING = from the very first row of the partition (the beginning).\n",
    ">>CURRENT ROW = up to the row you are currently on.\n",
    ">>So together:\n",
    "“Start from the first row and include everything up to the current row.”*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eb56c66-dcee-4ff3-86e0-263f4d5be08d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Custom Code:\n",
    "\n",
    "Want to show bucket names instead of numbers in NTILE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "197d2197-0dfe-4e0f-a02e-e9f119dd7ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "/*\n",
    "Show as group 1, group 2, group 3.. etc\n",
    "*/\n",
    "SELECT emp_name,\n",
    "       salary,\n",
    "       CONCAT('Group ', NTILE(3) OVER (ORDER BY salary DESC)) AS bucket_label\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af5ab3a-c68c-464c-ad49-df62fe024a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name,\n",
    "       salary,\n",
    "       NTILE(3) OVER (ORDER BY salary DESC) AS bucket_num,\n",
    "       CASE NTILE(3) OVER (ORDER BY salary DESC)\n",
    "            WHEN 1 THEN 'High'\n",
    "            WHEN 2 THEN 'Medium'\n",
    "            WHEN 3 THEN 'Low'\n",
    "       END AS bucket_label\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f830cd74-1a98-47b3-a9ac-00e04bc1fa44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "WITH labels AS (\n",
    "    SELECT 1 AS bucket, 'High' AS label UNION ALL\n",
    "    SELECT 2, 'Medium' UNION ALL\n",
    "    SELECT 3, 'Low'\n",
    ")\n",
    "SELECT e.emp_name,\n",
    "       e.salary,\n",
    "       e.bucket_num,\n",
    "       l.label AS bucket_label\n",
    "FROM (\n",
    "    SELECT emp_name, salary,\n",
    "           NTILE(3) OVER (ORDER BY salary DESC) AS bucket_num\n",
    "    FROM data_engineering_practice.sql.employees\n",
    ") e\n",
    "JOIN labels l\n",
    "  ON e.bucket_num = l.bucket;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "858f713f-83bb-49fe-bd5b-d6026f06e89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Handle Null Value - Not coaleas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c17f572-e591-4bee-9d05-8f81ad407aae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE or replace TABLE data_engineering_practice.sql.emp_ids (\n",
    "  emp_id INT PRIMARY KEY,\n",
    "  aadhaar VARCHAR(12)\n",
    ");\n",
    "\n",
    "INSERT INTO data_engineering_practice.sql.emp_ids VALUES\n",
    "(1,NULL),\n",
    "(2,NULL),\n",
    "(3,NULL),\n",
    "(4,'567856785678'),\n",
    "(5,NULL),\n",
    "(6,'999988887777'),\n",
    "(7,NULL),\n",
    "(8,NULL),\n",
    "(9,NULL),\n",
    "(10,NULL);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf458a6f-893f-4330-883d-d7fcb51d54ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_id,\n",
    "       aadhaar,\n",
    "       CASE \n",
    "         -- if forward-fill is still null (happens at the very beginning),\n",
    "         -- then use the next non-null value\n",
    "         WHEN LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) IS NULL\n",
    "         THEN FIRST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n",
    "         \n",
    "         -- otherwise, just use the forward-filled value\n",
    "         ELSE LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "       END AS aadhaar_filled\n",
    "FROM data_engineering_practice.sql.emp_ids\n",
    "ORDER BY emp_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2f1efd8-e32e-48c2-bee8-4a19f87d17e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1️⃣ The problem we’re solving\n",
    "\n",
    "Normally, we want to “fill down” the Aadhaar values if they’re missing.\n",
    "\n",
    "But if the first row(s) are NULL, forward-filling has nothing to copy yet… so it stays NULL.\n",
    "\n",
    "That’s where our CASE comes in: it says “if you can’t fill from the past, then look into the future.”\n",
    "\n",
    "2️⃣ The key logic (the CASE)\n",
    "CASE \n",
    "  WHEN (forward_fill) IS NULL\n",
    "  THEN (back_fill)\n",
    "  ELSE (forward_fill)\n",
    "END\n",
    "\n",
    "\n",
    "Think of it as:\n",
    "👉 “Check the forward-fill result. If it’s NULL, fall back to the back-fill. Otherwise, stick with the forward-fill.”\n",
    "\n",
    "3️⃣ What’s “forward-fill”?\n",
    "\n",
    "This line:\n",
    "\n",
    "LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "  OVER (ORDER BY emp_id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "\n",
    "\n",
    "LAST_VALUE → “Give me the most recent Aadhaar value so far in the order of emp_id.”\n",
    "\n",
    "IGNORE NULLS → skip over blanks when looking back.\n",
    "\n",
    "Window frame (ROWS BETWEEN ...) → “Start at the very first row and look through the current row.”\n",
    "\n",
    "So, it’s like dragging the last non-null value downward.\n",
    "\n",
    "4️⃣ What’s “back-fill”?\n",
    "\n",
    "This line:\n",
    "\n",
    "FIRST_VALUE(aadhaar) IGNORE NULLS \n",
    "  OVER (ORDER BY emp_id ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n",
    "\n",
    "\n",
    "FIRST_VALUE → “Give me the first Aadhaar I see in this window.”\n",
    "\n",
    "Window frame (from current row to the end) → looks ahead in the table.\n",
    "\n",
    "With IGNORE NULLS, it finds the next non-null Aadhaar.\n",
    "\n",
    "So, if forward-fill fails (like at the top), we borrow the next available non-null value.\n",
    "\n",
    "5️⃣ Together in the CASE\n",
    "\n",
    "If forward-fill is NULL → use back-fill (look ahead).\n",
    "\n",
    "Otherwise → use forward-fill (look behind).\n",
    "\n",
    "This ensures:\n",
    "\n",
    "The first row(s) don’t stay empty if they start as NULL.\n",
    "\n",
    "All middle rows get values carried forward.\n",
    "\n",
    "Multiple consecutive nulls are handled smoothly.\n",
    "\n",
    "✅ Quick mental image:\n",
    "\n",
    "Forward-fill = dragging values downwards.\n",
    "\n",
    "Back-fill = pulling values upwards.\n",
    "\n",
    "CASE = chooses which one makes sense at that moment."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "Windows Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
