{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c6272e8-cf31-4376-a2e3-e4fa91ac01c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "88f73782-76c0-4fa7-85cf-08d8d0f0f385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE or replace TABLE data_engineering_practice.sql.employees (\n",
    "    emp_id INT,\n",
    "    emp_name VARCHAR(50),\n",
    "    department VARCHAR(50),\n",
    "    salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO data_engineering_practice.sql.employees VALUES\n",
    "(1, 'Amit',   'HR',      40000),\n",
    "(2, 'Neha',   'HR',      50000),\n",
    "(3, 'Ritu',   'HR',      50000),\n",
    "(4, 'Raj',    'IT',      60000),\n",
    "(5, 'Simran', 'IT',      70000),\n",
    "(6, 'Vikram', 'IT',      70000),\n",
    "(7, 'Arjun',  'Finance', 45000),\n",
    "(8, 'Meena',  'Finance', 55000),\n",
    "(9, 'Kabir',  'Finance', 55000);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22858eb8-2ff9-4fa0-93bb-3745107b07f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. ROW_NUMBER()\n",
    "\n",
    "Gives a unique number to each row within a group based on order. Even if two rows tie, they still get different numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3729477-d006-404a-85d9-666f7fcc4880",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       ROW_NUMBER() OVER (PARTITION BY department ORDER BY salary DESC) AS row_num\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>In each department, employees are sorted by salary (highest ‚Üí lowest).\n",
    ">>Then they are numbered 1, 2, 3 ‚Ä¶ without skipping.\n",
    ">>Useful when you want to pick the top-N employees in each department.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "673d71e2-9e8d-43fb-bdc2-157eb0baed1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. RANK()\n",
    "\n",
    "Similar to ROW_NUMBER(), but if two rows tie, they get the same rank. The next rank jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947a1f42-6740-48b6-bab2-ed0b3222cb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS rank_pos\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>If two employees have the same salary, both are rank 1.\n",
    ">>The next employee will get rank 3, not 2.\n",
    ">>Useful in contests or leaderboards where ties share the same position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6d650cb-db9d-4de1-8ee8-4cf27766deea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. DENSE_RANK()\n",
    "\n",
    "Like RANK(), but it doesn‚Äôt skip numbers after ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c219c5ef-64b6-4501-8254-731e608db68a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       DENSE_RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS dense_rank_pos\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>Neha & Ritu both rank 1, Amit becomes rank 2 (not 3).\n",
    ">>Keeps numbers compact.\n",
    ">>Often used in reporting when you don‚Äôt want gaps in rank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56cae39-4389-4445-8851-ab113da0b92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. NTILE(n)\n",
    "\n",
    "Splits rows into n roughly equal groups (buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbcbcc9-7ab2-4894-8d18-8075a5bcca08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       NTILE(3) OVER (ORDER BY salary DESC) AS bucket\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cab3b60-d924-485f-9313-3eaa9a8eb203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. LAG()\n",
    "\n",
    "Fetches the previous row‚Äôs value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef3d3f5-0a8b-4971-adf3-4fb048edebaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       LAG(salary) OVER (ORDER BY salary) AS prev_salary\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For each employee, shows what the previous employee‚Äôs salary was.\n",
    ">>First row has NULL because no one is before it.\n",
    ">>Useful for calculating differences between rows (e.g. salary increase from previous).*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5325def0-58ce-44f7-94ba-8aa15666c501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. LEAD()\n",
    "\n",
    "Fetches the next row‚Äôs value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64f534f1-f37c-4138-8717-484c5eeac557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       LEAD(salary) OVER (ORDER BY salary) AS next_salary\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For each employee, shows what the next employee‚Äôs salary is.\n",
    ">>Last row has NULL because no one is after it.\n",
    ">>Useful for comparing current vs. next record.*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cf7195c-f3e4-40db-a8f7-e9872336cbf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 7. SUM() / AVG() with OVER\n",
    "\n",
    "Aggregate functions over a partition, but rows are not collapsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b08e0d3c-082d-4984-9986-b7d295f01a81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, department, salary,\n",
    "       SUM(salary) OVER (PARTITION BY department) AS dept_total,\n",
    "       AVG(salary) OVER (PARTITION BY department) AS dept_avg\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>For every employee, you see their department‚Äôs total & average salary.\n",
    ">>Unlike GROUP BY, you don‚Äôt lose row-level detail.\n",
    ">>Perfect for showing both employee-level and group-level info in one query.*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d0000aa-80b1-4800-ba54-77bc9bb4a3bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8. Running Total (Cumulative SUM)\n",
    "\n",
    "Keeps adding row by row, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f04d01ef-7a2b-45c3-9434-bf418b1ea62d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name, salary,\n",
    "       SUM(salary) OVER (ORDER BY salary\n",
    "                         ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total\n",
    "FROM data_engineering_practice.sql.employees;\n",
    "\n",
    "/*\n",
    ">>Salaries are ordered (lowest ‚Üí highest).\n",
    ">>Running total is computed row by row.\n",
    ">>Useful for things like cumulative sales or progressive totals.\n",
    "\n",
    ">>UNBOUNDED PRECEDING = from the very first row of the partition (the beginning).\n",
    ">>CURRENT ROW = up to the row you are currently on.\n",
    ">>So together:\n",
    "‚ÄúStart from the first row and include everything up to the current row.‚Äù*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eb56c66-dcee-4ff3-86e0-263f4d5be08d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Custom Code:\n",
    "\n",
    "Want to show bucket names instead of numbers in NTILE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "197d2197-0dfe-4e0f-a02e-e9f119dd7ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "/*\n",
    "Show as group 1, group 2, group 3.. etc\n",
    "*/\n",
    "SELECT emp_name,\n",
    "       salary,\n",
    "       CONCAT('Group ', NTILE(3) OVER (ORDER BY salary DESC)) AS bucket_label\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af5ab3a-c68c-464c-ad49-df62fe024a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_name,\n",
    "       salary,\n",
    "       NTILE(3) OVER (ORDER BY salary DESC) AS bucket_num,\n",
    "       CASE NTILE(3) OVER (ORDER BY salary DESC)\n",
    "            WHEN 1 THEN 'High'\n",
    "            WHEN 2 THEN 'Medium'\n",
    "            WHEN 3 THEN 'Low'\n",
    "       END AS bucket_label\n",
    "FROM data_engineering_practice.sql.employees;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f830cd74-1a98-47b3-a9ac-00e04bc1fa44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "WITH labels AS (\n",
    "    SELECT 1 AS bucket, 'High' AS label UNION ALL\n",
    "    SELECT 2, 'Medium' UNION ALL\n",
    "    SELECT 3, 'Low'\n",
    ")\n",
    "SELECT e.emp_name,\n",
    "       e.salary,\n",
    "       e.bucket_num,\n",
    "       l.label AS bucket_label\n",
    "FROM (\n",
    "    SELECT emp_name, salary,\n",
    "           NTILE(3) OVER (ORDER BY salary DESC) AS bucket_num\n",
    "    FROM data_engineering_practice.sql.employees\n",
    ") e\n",
    "JOIN labels l\n",
    "  ON e.bucket_num = l.bucket;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "858f713f-83bb-49fe-bd5b-d6026f06e89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Handle Null Value - Not coaleas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c17f572-e591-4bee-9d05-8f81ad407aae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE or replace TABLE data_engineering_practice.sql.emp_ids (\n",
    "  emp_id INT PRIMARY KEY,\n",
    "  aadhaar VARCHAR(12)\n",
    ");\n",
    "\n",
    "INSERT INTO data_engineering_practice.sql.emp_ids VALUES\n",
    "(1,NULL),\n",
    "(2,NULL),\n",
    "(3,NULL),\n",
    "(4,'567856785678'),\n",
    "(5,NULL),\n",
    "(6,'999988887777'),\n",
    "(7,NULL),\n",
    "(8,NULL),\n",
    "(9,NULL),\n",
    "(10,NULL);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf458a6f-893f-4330-883d-d7fcb51d54ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT emp_id,\n",
    "       aadhaar,\n",
    "       CASE \n",
    "         -- if forward-fill is still null (happens at the very beginning),\n",
    "         -- then use the next non-null value\n",
    "         WHEN LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) IS NULL\n",
    "         THEN FIRST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n",
    "         \n",
    "         -- otherwise, just use the forward-filled value\n",
    "         ELSE LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "                OVER (ORDER BY emp_id\n",
    "                      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "       END AS aadhaar_filled\n",
    "FROM data_engineering_practice.sql.emp_ids\n",
    "ORDER BY emp_id;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2f1efd8-e32e-48c2-bee8-4a19f87d17e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1Ô∏è‚É£ The problem we‚Äôre solving\n",
    "\n",
    "Normally, we want to ‚Äúfill down‚Äù the Aadhaar values if they‚Äôre missing.\n",
    "\n",
    "But if the first row(s) are NULL, forward-filling has nothing to copy yet‚Ä¶ so it stays NULL.\n",
    "\n",
    "That‚Äôs where our CASE comes in: it says ‚Äúif you can‚Äôt fill from the past, then look into the future.‚Äù\n",
    "\n",
    "2Ô∏è‚É£ The key logic (the CASE)\n",
    "CASE \n",
    "  WHEN (forward_fill) IS NULL\n",
    "  THEN (back_fill)\n",
    "  ELSE (forward_fill)\n",
    "END\n",
    "\n",
    "\n",
    "Think of it as:\n",
    "üëâ ‚ÄúCheck the forward-fill result. If it‚Äôs NULL, fall back to the back-fill. Otherwise, stick with the forward-fill.‚Äù\n",
    "\n",
    "3Ô∏è‚É£ What‚Äôs ‚Äúforward-fill‚Äù?\n",
    "\n",
    "This line:\n",
    "\n",
    "LAST_VALUE(aadhaar) IGNORE NULLS \n",
    "  OVER (ORDER BY emp_id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\n",
    "\n",
    "\n",
    "LAST_VALUE ‚Üí ‚ÄúGive me the most recent Aadhaar value so far in the order of emp_id.‚Äù\n",
    "\n",
    "IGNORE NULLS ‚Üí skip over blanks when looking back.\n",
    "\n",
    "Window frame (ROWS BETWEEN ...) ‚Üí ‚ÄúStart at the very first row and look through the current row.‚Äù\n",
    "\n",
    "So, it‚Äôs like dragging the last non-null value downward.\n",
    "\n",
    "4Ô∏è‚É£ What‚Äôs ‚Äúback-fill‚Äù?\n",
    "\n",
    "This line:\n",
    "\n",
    "FIRST_VALUE(aadhaar) IGNORE NULLS \n",
    "  OVER (ORDER BY emp_id ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n",
    "\n",
    "\n",
    "FIRST_VALUE ‚Üí ‚ÄúGive me the first Aadhaar I see in this window.‚Äù\n",
    "\n",
    "Window frame (from current row to the end) ‚Üí looks ahead in the table.\n",
    "\n",
    "With IGNORE NULLS, it finds the next non-null Aadhaar.\n",
    "\n",
    "So, if forward-fill fails (like at the top), we borrow the next available non-null value.\n",
    "\n",
    "5Ô∏è‚É£ Together in the CASE\n",
    "\n",
    "If forward-fill is NULL ‚Üí use back-fill (look ahead).\n",
    "\n",
    "Otherwise ‚Üí use forward-fill (look behind).\n",
    "\n",
    "This ensures:\n",
    "\n",
    "The first row(s) don‚Äôt stay empty if they start as NULL.\n",
    "\n",
    "All middle rows get values carried forward.\n",
    "\n",
    "Multiple consecutive nulls are handled smoothly.\n",
    "\n",
    "‚úÖ Quick mental image:\n",
    "\n",
    "Forward-fill = dragging values downwards.\n",
    "\n",
    "Back-fill = pulling values upwards.\n",
    "\n",
    "CASE = chooses which one makes sense at that moment."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "Windows Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
